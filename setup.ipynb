{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e131ab1",
   "metadata": {},
   "source": [
    "# Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe054284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchvision torchaudio\n",
    "# !pip install transformers  datasets tokenizers\n",
    "# !pip install trl peft wandb\n",
    "# !pip install huggingface_hub\n",
    "# !pip install accelerate==1.5.0\n",
    "# !pip install torch==2.8.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b6c276",
   "metadata": {},
   "source": [
    "# Model download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72326b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import snapshot_download\n",
    "# model_path = snapshot_download(repo_id=\"Qwen/Qwen2.5-3B-Instruct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e19ae4",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "715acee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cdf4f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vivekchaudhary/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/vivekchaudhary/anaconda3/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <C1CC76AA-CD55-3E10-9064-29676E3E2535> /Users/vivekchaudhary/anaconda3/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Expected in:     <B6BD92AE-4D03-3F92-9E03-2E2594A12866> /Users/vivekchaudhary/anaconda3/lib/python3.11/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dc84443059044d2817e2fbf5e7443a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________\n",
      "Mahabalipuram (also spelled as Mamallapuram) is an ancient town located on the southeastern coast of India, in the Kancheepuram district of the state of Tamil Nadu. It is approximately 64 kilometers south of Chennai, the capital city of Tamil Nadu.\n",
      "\n",
      "Mahabalipuram is known for its stunning rock-cut temples and architectural marvels carved into cliffs during the reign of the Pallava dynasty between the 7th and 9th centuries CE. These structures include the famous Shore Temple, which features a towering vimana (towering spire), and numerous other temples, caves, and monuments that showcase the architectural prowess of the Pallavas.\n",
      "\n",
      "The site has been recognized as a UNESCO World Heritage Site since 1984. Mahabalipuram remains an important archaeological and cultural landmark in India, attracting visitors from around the world to explore its rich history and impressive architecture.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"Qwen/Qwen2.5-3B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# Test question\n",
    "question = \"Where is Mahabalipuram ?\"\n",
    "\n",
    "# Format input\n",
    "messages = [{\"role\": \"user\", \"content\": question}]\n",
    "text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "# Generate\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(model.device)\n",
    "outputs = model.generate(**inputs, max_new_tokens=256, temperature=0.7)\n",
    "response = tokenizer.decode(outputs[0][len(inputs.input_ids[0]):], skip_special_tokens=True)\n",
    "\n",
    "print('______________________________________________________')\n",
    "\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
